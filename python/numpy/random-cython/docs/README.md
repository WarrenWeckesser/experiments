Notes on the implementation of the rejection method for the Zipfian distribution
--------------------------------------------------------------------------------

This is not a tutorial on the rejection method.  The method is described in the
wikipedia article [Rejection sampling](https://en.wikipedia.org/wiki/Rejection_sampling),
and a web search should point to at least a few tutorials.

These notes provide the details for the implementation of the method for the
Zipfian distribution (implemented in SciPy as `scipy.stats.zipfian`).

The PMF for the Zipfian distribution is

$$
    p(k, a, n) = \frac{k^{-a}}{H_{n, a}}, \quad k \in \\{1, 2, ..., n\\}
$$

where the *generalized harmonic number*

$$
    H_{n, a} = \sum_{k = 1}^{n} k^{-a}
$$

is the normalization constant required to make $p$ a PMF.

For the plots, I'll use the parameters `a = 0.95` and `n = 7`.

Here is a plot of the PMF:

![](https://github.com/WarrenWeckesser/experiments/blob/main/python/numpy/random-cython/docs/zipfian_pmf.png)

Extend this distribution to a continuous distribution with a piecewise constant PDF
$f(x, a, n)$ on support $1 \le x \lt n + 1$.

$$
    f(x, a, n) = \frac{\lfloor k \rfloor^{-a}}{H_{n, a}}, \quad 1 \le x < n + 1
$$

If we can generate variates from this continuous distribution, we can truncate those
variates to their integer part to get variates from the discrete Zipfian distribution.

![](https://github.com/WarrenWeckesser/experiments/blob/main/python/numpy/random-cython/docs/zipfian_pdf.png)


The *dominating distribution* is a distribution with a PDF $g(x, a, n)$ such that for some
$M(a, n)$, $M(a, n) g(x, a, n) \ge h(x, a, n)$ on the support. (In the wikipedia article
linked above, this is called the *proposal distribution*.)  This is the distribution that
we'll use to generate candidate random variates.  For the Zipfian distribution, we can use

$$
    g(x, a, n)
     = \frac{1}{B(n, 1 - a) + 1}
       \begin{cases}
         1                       & 1 \le x < 2 &       \\
         \left(x - 1\right)^{-a} & 2 \le x < n + 1     \\
         0                       & \textrm{otherwise}
       \end{cases}
$$

where $B(x, \lambda)$ is the 
[Box-Cox power transformation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.boxcox.html).  (A little calculus will show that $g(x, a, n)$ is, in fact, a PDF.)

The scaling constant $M(a, n)$ is then

$$
    M(a, n) = \frac{B(n, 1 - a) + 1}{H_{n, a}}
$$

This plot shows the target PDF $f(x, a, n)$ and the scaled dominating PDF
$M(a, n) g(x, a, n)$. The plot shows that $g(x, a, n)$ is a dominating PDF for $f(x, a, n)$,
and that on the interval $1 \le x < 2$, $M(a, n)g(x, a, n) \equiv f(x, a, n)$.

![](https://github.com/WarrenWeckesser/experiments/blob/main/python/numpy/random-cython/docs/zipfian_pdf_and_dom.png)

To generate variates from the dominating distribution, we'll use the inversion method:
generate uniform variates and pass them through the inverse of the CDF.  We get the
CDF $G(x, a, n)$ by integrating the PDF $g(x, a, n)$.  On the interval
$1 \le x \le n + 1$, we have

$$
    G(x, a, n)
     =  \frac{1}{B(n, 1 - a) + 1}
        \begin{cases}
         x - 1                                      & 1 \le x < 2 &       \\
         \frac{\left(x - 1\right)^{1-a} - a}{1 - a} & 2 \le x < n + 1
       \end{cases}
$$

which can be written in terms of the Box-Cox transformation as

$$
    G(x, a, n)
     = \frac{1}{B(n, 1 - a) + 1}
       \begin{cases}
         x - 1                & 1 \le x < 2 &     \\
         B(x - 1, 1 - a) + 1  & 2 \le x < n + 1
       \end{cases}
$$

(That is the "little bit of calculus" mentioned above. Now it is easy to verify that
$G(n + 1, a, n) = 1$.)

This plot shows $G(x, 0.95, 7)$:

![](https://github.com/WarrenWeckesser/experiments/blob/main/python/numpy/random-cython/docs/zipfian_dom_cdf.png)

Once a candidate $X$ has been generated by the inversion method,
another uniform variate $U[0, 1)$ is generated, and $X$ is accepted if

$$
    U M(a, n) g(X, a, n) \le h(X, a, n)
$$

Substituting the definition of $M(a, n)$ into that inequality and rearranging a bit,
this condition is equivalent to

$$
    U (B(n, 1 - a) + 1) g(X, a, n) \le H_{n, a} f(X, a, n)
$$

or

$$
    U \tilde{g}(X, a, n) \le \tilde{f}(X, a, n)
$$

where $\tilde{f}$ and $\tilde{g}$ are the nonnormalized PDFs (i.e. without their
normalizing constants).  This means we can perform the rejection/acceptance test
without computing $H_{n, a}$.

Note that on the interval $1 \le x < 2$, $\tilde{g}(x, a, n) \equiv \tilde{f}(x, a, n)$.
So if the candidate $X$ is in this interval, it will always be accepted, and
there is no need to generate $U$.

When $X$ is accepted, $\lfloor X \rfloor$ is a variate from the discrete
Zipfian distribution.

$M(a, n)$ gives the expected number of iterations performed by the rejection method.
Numerical experiments show that $M(a, n) < 1.25$.  For each $n$, the maximum
of $M(a, n)$ occurs near $a = 3$, as seen in the following plot:

![](https://github.com/WarrenWeckesser/experiments/blob/main/python/numpy/random-cython/docs/rejection_scaling_constant_plots.png)
